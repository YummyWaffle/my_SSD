{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 6> SSD Implementation </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size= 5>监督深度学习的几个核心组成与分析的切入点</font>\n",
    "* <font size= 4>数据集</font>\n",
    "  * <font size= 3>深度学习是数据驱动的模型，数据起到最核心的作用，在监督学习中，数据集囊括数据与标签</font>\n",
    "* <font size= 4>表示</font>\n",
    "  * <font size= 3>经数学证明，深度学习可以以任意精度拟合连续函数，如果视深度学习为工具、黑盒子，怎么合理地、数字化地描述工程，当前表示是否利于收敛是非常重要的问题</font>\n",
    "  > Reference - Neural Network with Unbounded Activation Functions is Universal Approximator  https://arxiv.org/abs/1505.03654\n",
    "* <font size= 4>模型</font>\n",
    "  * <font size= 3>深度学习中模型部分主要工作是估计一个函数 $f$ 建立数据与目标间的关系</font>\n",
    "  * <font size= 3>以目标检测为例，实质上希望建立关系 $label, bounding box = f(image)$ ，模型即是其中的 $f$</font>\n",
    "* <font size= 4>评估</font>\n",
    "  * <font size= 3>度量模型与期望间的差异，以损失函数的形式表示，常用的损失函数包含：MSELoss / Cross Entropy / L1Loss等等</font>\n",
    "* <font size= 4>优化</font>\n",
    "  * <font size= 3>根据评估的结果，对模型进行调整，使得模型逐步变好</font>\n",
    "  * <font size= 3>深度学习常用基于梯度的优化算法，通过反向传播(BP)快速求解梯度，利用SGD、Adam等算法进行调整</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import xml.etree.ElementTree as ET\n",
    "import math\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 5> Part 1 数据集 </font>\n",
    "\n",
    "<font size = 3>DIOR数据集，转化为PASCAL VOC格式</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ssd_voc_loader(data.Dataset):\n",
    "\n",
    "    CLASSES = ['airplane', 'airport', 'baseballfield', 'basketballcourt', 'bridge', 'chimney', 'dam',\n",
    "               'Expressway-Service-area', 'Expressway-toll-station', 'golffield', 'groundtrackfield', \n",
    "               'harbor', 'overpass','ship', 'stadium', 'storagetank', 'tenniscourt', 'trainstation', \n",
    "               'vehicle','windmill','background']\n",
    "               \n",
    "    def __init__(self,dataset_folder,ssd_version=300,train_loader=True):\n",
    "        self.image_folder = dataset_folder + '/VOC2007/JPEGImages'\n",
    "        self.anno_folder = dataset_folder + '/VOC2007/Annotations'\n",
    "        self.txt_folder = dataset_folder + '/VOC2007/ImageSets/Main'\n",
    "        if train_loader:\n",
    "            self.txt_folder += '/train.txt'\n",
    "        else:\n",
    "            self.txt_folder += '/test.txt'\n",
    "        # Read sets\n",
    "        self.file_sets = []\n",
    "        f = open(self.txt_folder,'r')\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            line = line.strip().split()\n",
    "            self.file_sets.extend(line)\n",
    "        self.file_num = len(self.file_sets)\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        # Parse Image\n",
    "        img_path = self.image_folder + '/' + self.file_sets[index] + '.jpg'\n",
    "        img = cv2.imread(img_path)\n",
    "        # Parse Annotations\n",
    "        anno_path = self.anno_folder + '/' + self.file_sets[index] + '.xml'\n",
    "        root = ET.parse(anno_path).getroot()\n",
    "        img_width = float(root.find('size').find('width').text)\n",
    "        img_height = float(root.find('size').find('height').text)\n",
    "        objs = root.findall('object')\n",
    "        for obj in objs:\n",
    "            labels = self.CLASSES.index(obj.find('name').text)\n",
    "            xmin = int(obj.find('bndbox').find('xmin').text)\n",
    "            xmax = int(obj.find('bndbox').find('xmax').text)\n",
    "            ymin = int(obj.find('bndbox').find('ymin').text)\n",
    "            ymax = int(obj.find('bndbox').find('ymax').text)\n",
    "            cv2.rectangle(img,(xmin,ymin),(xmax,ymax),(0,0,255),3)\n",
    "        return img[:,:,::-1]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.file_num\n",
    "\n",
    "dataset = ssd_voc_loader('D:/0426DIOR/DIOR/VOCdevkit')\n",
    "img = dataset[522]\n",
    "print('Dataset Sample Number: '+ str(len(dataset)))\n",
    "plt.imshow(img)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 5> Part 2 表示 </font>\n",
    "\n",
    "<font size = 3> 通过以下表示，有效地限制了四个修正参数的范围，利于神经网络收敛 </font>\n",
    "\n",
    "$$t_x = \\frac{x-x_a}{w_a}$$\n",
    "\n",
    "$$t_y = \\frac{y-y_a}{h_a}$$\n",
    "\n",
    "$$t_w = \\ln{\\frac{w}{w_a}}$$\n",
    "\n",
    "$$t_w = \\ln{\\frac{h}{h_a}}$$\n",
    "\n",
    "![jupyter](./notebookpic/representation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 5> Part 3 模型 </font>\n",
    "\n",
    "<font size = 3> SSD结构 </font>\n",
    "\n",
    "![jupyter](./notebookpic/ssd_structure.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 3> VGG-16 结构 </font>\n",
    "![jupyter](./notebookpic/VGG16.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv_bn_relu(nn.Module):\n",
    "    def __init__(self,inplane,plane,kernel_size=3,stride=1,padding=1,dilation=1):\n",
    "        super(conv_bn_relu,self).__init__()\n",
    "        self.conv = nn.Conv2d(inplane,plane,kernel_size,stride,padding,dilation)\n",
    "        self.bn = nn.BatchNorm2d(plane)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "    def forward(self,x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class SSD_VGG(nn.Module):\n",
    "    arch_setting = {\n",
    "        11: (1, 1, 2, 2, 2),\n",
    "        13: (2, 2, 2, 2, 2),\n",
    "        16: (2, 2, 3, 3, 3),\n",
    "        19: (2, 2, 4, 4, 4)\n",
    "    }\n",
    "    def __init__(self,depth=16,use_bn=True):\n",
    "        super(SSD_VGG,self).__init__()\n",
    "        # Only Support VGG-16\n",
    "        assert(depth==16)\n",
    "        self.inplane = 3\n",
    "        self.plane = 64\n",
    "        self.stage_settings = self.arch_setting[depth]\n",
    "        self.features = []\n",
    "        for i,stage_setting in enumerate(self.stage_settings):\n",
    "            if(i != 4):\n",
    "                layer = self._make_layers(conv_bn_relu,stage_setting,self.plane)\n",
    "                self.features.extend(layer)\n",
    "                self.plane = int(self.plane * 2)\n",
    "            else:\n",
    "                self.plane = int(self.plane / 2)\n",
    "                layer =  self._make_layers(conv_bn_relu,stage_setting,self.plane,with_pool=False)\n",
    "                self.features.extend(layer)\n",
    "        self.features = nn.ModuleList(self.features)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=3,stride=1,padding=1)\n",
    "        self.fc6 = conv_bn_relu(self.inplane,1024)\n",
    "        self.fc7 = conv_bn_relu(1024,1024,kernel_size=1,stride=1,padding=0,dilation=1)\n",
    "            \n",
    "        \n",
    "    def _make_layers(self,block_type,block_nums,plane,with_pool=True):\n",
    "        layers = []\n",
    "        layers.append(block_type(self.inplane,plane))\n",
    "        self.inplane = plane\n",
    "        for i in range(1,block_nums):\n",
    "            layers.append(block_type(self.inplane,plane))\n",
    "        if with_pool:\n",
    "            layers.append(nn.MaxPool2d(kernel_size=2,stride=2,ceil_mode=True))\n",
    "        return layers\n",
    "    \n",
    "    def forward(self,x):\n",
    "        # output conv4_3's feature map whose index is 12\n",
    "        outs = []\n",
    "        for i,layers in enumerate(self.features):\n",
    "            x = layers(x)\n",
    "            if(i == 12):\n",
    "                outs.append(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.fc6(x)\n",
    "        # output fc7's feature map\n",
    "        x = self.fc7(x)\n",
    "        outs.append(x)\n",
    "        return outs\n",
    "    \n",
    "model = SSD_VGG().cuda()\n",
    "#print(model)\n",
    "in_tsr = torch.randn(size=(1,3,300,300)).cuda()\n",
    "out_tsr = model(in_tsr)\n",
    "for out in out_tsr:\n",
    "    print(out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSD300(nn.Module):\n",
    "    def __init__(self,box_settings=[4,6,6,6,4,4],\n",
    "                      out_channels = [512,1024,512,256,256,256],\n",
    "                      class_num=20):\n",
    "        super(SSD300,self).__init__()\n",
    "        self.class_num = class_num\n",
    "        self.base_net = SSD_VGG()\n",
    "        self.extra_layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1024,256,kernel_size=1,stride=1,padding=0,dilation=1),\n",
    "            nn.Conv2d(256,512,kernel_size=3,stride=2,padding=1,dilation=1),\n",
    "        )\n",
    "        self.extra_layer2 = nn.Sequential(\n",
    "            nn.Conv2d(512,128,kernel_size=1,stride=1,padding=0,dilation=1),\n",
    "            nn.Conv2d(128,256,kernel_size=3,stride=2,padding=1,dilation=1),\n",
    "        )\n",
    "        self.extra_layer3 = nn.Sequential(\n",
    "            nn.Conv2d(256,128,kernel_size=1,stride=1,padding=0,dilation=1),\n",
    "            nn.Conv2d(128,256,kernel_size=3,stride=2,padding=1,dilation=1),\n",
    "        )\n",
    "        self.extra_layer4 = nn.Sequential(\n",
    "            nn.Conv2d(256,128,kernel_size=1,stride=1,padding=0,dilation=1),\n",
    "            nn.Conv2d(128,256,kernel_size=3,stride=1),\n",
    "        )\n",
    "        self.cls_convs = []\n",
    "        self.reg_convs = []\n",
    "        for i,box_setting in enumerate(box_settings):\n",
    "            self.cls_convs.append(nn.Conv2d(out_channels[i],box_setting*(self.class_num+1),kernel_size=3,padding=1))\n",
    "            self.reg_convs.append(nn.Conv2d(out_channels[i],box_setting*4,kernel_size=3,padding=1))\n",
    "        self.cls_convs = nn.ModuleList(self.cls_convs) \n",
    "        self.reg_convs = nn.ModuleList(self.reg_convs)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        # Get Feature Maps Here\n",
    "        feats = []\n",
    "        x = self.base_net(x)\n",
    "        feats.extend(x)\n",
    "        x = x[1]\n",
    "        x = self.extra_layer1(x)\n",
    "        feats.append(x)\n",
    "        x = self.extra_layer2(x)\n",
    "        feats.append(x)\n",
    "        x = self.extra_layer3(x)\n",
    "        feats.append(x)\n",
    "        x = self.extra_layer4(x)\n",
    "        feats.append(x)\n",
    "        # Pass All The Reg & Cls Module\n",
    "        cls_pred = []\n",
    "        reg_pred = []\n",
    "        for i,cls_conv in enumerate(self.cls_convs):\n",
    "            cls_pred.append(cls_conv(feats[i]).permute(0,2,3,1).contiguous())\n",
    "            reg_pred.append(self.reg_convs[i](feats[i]).permute(0,2,3,1).contiguous())\n",
    "        cls_pred = torch.cat([c.view(c.size(0),-1,self.class_num+1) for c in cls_pred],1)\n",
    "        reg_pred = torch.cat([r.view(r.size(0),-1,4) for r in reg_pred],1)\n",
    "        return cls_pred,reg_pred\n",
    "    \n",
    "model = SSD300().cuda()\n",
    "#print(model)\n",
    "test_tsr = torch.randn(size=(1,3,300,300)).cuda()\n",
    "cls,reg = model(test_tsr)\n",
    "print(cls.size(),reg.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 3> Prior Box Generating </font>\n",
    "\n",
    "<font size = 3> Anchor锚框是作为强先验的存在，对于SSD的多尺度特征图结构，很自然地会有一个想法，用尺寸小的特征图探测大目标，用尺寸大的特征图探测小目标，因此在不同的特征图上，生成不同尺寸的先验锚框 </font>\n",
    "$$s_k=s_{max}+\\frac{s_{max}-s_{min}}{5}(k-1),k\\in[1,6]$$\n",
    "以SSD-300为例，$s_{min}\\times300$代表conv4_3输出特征图生成anchor的基准尺寸，$s_{max}\\times300$代表最后一个特征图生成anchor的基准尺寸，中间层anchor的基准尺寸均匀排布，以$s_{min}=0.2,s_{max}=0.8$为例，各层对应的基准尺寸如下:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_min = 0.2\n",
    "s_max = 0.8\n",
    "default_size  = []\n",
    "for i in range(1,7):\n",
    "    s_k = s_min+(s_max-s_min)*(i-1)/(6-1)\n",
    "    version_specific_size = s_k * 300\n",
    "    default_size.append(version_specific_size)\n",
    "for i,size in enumerate(default_size):\n",
    "    print('feature_map index: %d default box size: %.f'%(i+1,size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 3>对于某一层的特征图，其生成的锚框包括$\\{s_{k},\\sqrt{s_{k}\\times s_{k+1}},s_{k,ratio1},s_{k.ratio2},...,s_{k_ratio}\\}$</font>\n",
    "\n",
    "<font size = 3>尺度变换的公式为$w=\\frac{s_k}{\\sqrt{ratio}}$ $h=s_k \\times \\sqrt{ratio}$</font>\n",
    "\n",
    "<font size = 3> 将锚框平铺到原图上，与标签计算交并比 $IoU = \\frac{A\\cap B}{A\\cup B}$ ， $IoU>0.5$ 为正样本,反之为负样本，即可以计算target </font>\n",
    "\n",
    "<font size = 3>下有生成效果</font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_k = 50\n",
    "s_kp1 = 60\n",
    "ratios = [2,3]\n",
    "box = []\n",
    "box1 = [50,50,s_k,s_k]\n",
    "box.append(box1)\n",
    "box2 = [50,50,math.sqrt(s_kp1*s_k),math.sqrt(s_kp1*s_k)]\n",
    "box.append(box2)\n",
    "for ratio in ratios:\n",
    "    w = s_k / math.sqrt(ratio)\n",
    "    h = s_k * math.sqrt(ratio)\n",
    "    box_temp = [50,50,w,h]\n",
    "    box.append(box_temp)\n",
    "\n",
    "img = np.zeros((100,100,3),dtype=np.uint8)\n",
    "img.fill(255)\n",
    "\n",
    "color = [(0,0,255),(255,0,0),(0,255,0),(255,0,255)]\n",
    "for i,boxi in enumerate(box):\n",
    "    tl_x = int(boxi[0]-boxi[2]/2.)\n",
    "    tl_y = int(boxi[1]-boxi[3]/2.)\n",
    "    br_x = int(boxi[0]+boxi[2]/2.)\n",
    "    br_y = int(boxi[1]+boxi[3]/2.)\n",
    "    cv2.rectangle(img,(tl_x,tl_y),(br_x,br_y),color[i],1)\n",
    "img2 = img[:,:,::-1]\n",
    "plt.imshow(img2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 5> Part 4 评估 </font>\n",
    "\n",
    "<font size = 3> 分类误差采用交叉熵Cross Entropy，定位误差使用Smooth L1 Loss避免误差过大导致不收敛问题 </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 5> Part 5 优化 </font>\n",
    "\n",
    "<font size = 3 > 非常灵活，使用SGD/Adam等等均可，本次复现使用的是SGD</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 5> Part 6 我的复现 </font>\n",
    "> <font size = 3> Github links of this code -  https://github.com/YummyWaffle/my_SSD </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run TrainSSD.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
